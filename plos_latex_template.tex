% Template for PLoS
% Version 3.5 March 2018
%
% % % % % % % % % % % % % % % % % % % % % %
%
% -- IMPORTANT NOTE
%
% This template contains comments intended 
% to minimize problems and delays during our production 
% process. Please follow the template instructions
% whenever possible.
%
% % % % % % % % % % % % % % % % % % % % % % % 
%
% Once your paper is accepted for publication, 
% PLEASE REMOVE ALL TRACKED CHANGES in this file 
% and leave only the final text of your manuscript. 
% PLOS recommends the use of latexdiff to track changes during review, as this will help to maintain a clean tex file.
% Visit https://www.ctan.org/pkg/latexdiff?lang=en for info or contact us at latex@plos.org.
%
%
% There are no restrictions on package use within the LaTeX files except that 
% no packages listed in the template may be deleted.
%
% Please do not include colors or graphics in the text.
%
% The manuscript LaTeX source should be contained within a single file (do not use \input, \externaldocument, or similar commands).
%
% % % % % % % % % % % % % % % % % % % % % % %
%
% -- FIGURES AND TABLES
%
% Please include tables/figure captions directly after the paragraph where they are first cited in the text.
%
% DO NOT INCLUDE GRAPHICS IN YOUR MANUSCRIPT
% - Figures should be uploaded separately from your manuscript file. 
% - Figures generated using LaTeX should be extracted and removed from the PDF before submission. 
% - Figures containing multiple panels/subfigures must be combined into one image file before submission.
% For figure citations, please use "Fig" instead of "Figure".
% See http://journals.plos.org/plosone/s/figures for PLOS figure guidelines.
%
% Tables should be cell-based and may not contain:
% - spacing/line breaks within cells to alter layout or alignment
% - do not nest tabular environments (no tabular environments within tabular environments)
% - no graphics or colored text (cell background color/shading OK)
% See http://journals.plos.org/plosone/s/tables for table guidelines.
%
% For tables that exceed the width of the text column, use the adjustwidth environment as illustrated in the example table in text below.
%
% % % % % % % % % % % % % % % % % % % % % % % %
%
% -- EQUATIONS, MATH SYMBOLS, SUBSCRIPTS, AND SUPERSCRIPTS
%
% IMPORTANT
% Below are a few tips to help format your equations and other special characters according to our specifications. For more tips to help reduce the possibility of formatting errors during conversion, please see our LaTeX guidelines at http://journals.plos.org/plosone/s/latex
%
% For inline equations, please be sure to include all portions of an equation in the math environment.  For example, x$^2$ is incorrect; this should be formatted as $x^2$ (or $\mathrm{x}^2$ if the romanized font is desired).
%
% Do not include text that is not math in the math environment. For example, CO2 should be written as CO\textsubscript{2} instead of CO$_2$.
%
% Please add line breaks to long display equations when possible in order to fit size of the column. 
%
% For inline equations, please do not include punctuation (commas, etc) within the math environment unless this is part of the equation.
%
% When adding superscript or subscripts outside of brackets/braces, please group using {}.  For example, change "[U(D,E,\gamma)]^2" to "{[U(D,E,\gamma)]}^2". 
%
% Do not use \cal for caligraphic font.  Instead, use \mathcal{}
%
% % % % % % % % % % % % % % % % % % % % % % % % 
%
% Please contact latex@plos.org with any questions.
%
% % % % % % % % % % % % % % % % % % % % % % % %

\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in]{geometry}

% amsmath and amssymb packages, useful for mathematical formulas and symbols
\usepackage{amsmath,amssymb}

% Use adjustwidth environment to exceed column width (see example table in text)
\usepackage{changepage}

% Use Unicode characters when possible
\usepackage[utf8x]{inputenc}

% textcomp package and marvosym package for additional characters
\usepackage{textcomp,marvosym}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

% Use nameref to cite supporting information files (see Supporting Information section for more info)
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% ligatures disabled
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% color can be used to apply background shading to table cells only
\usepackage[table]{xcolor}

% array package and thick rules for tables
\usepackage{array}

% create "+" rule type for thick vertical lines
\newcolumntype{+}{!{\vrule width 2pt}}

% create \thickcline for thick horizontal lines of variable length
\newlength\savedwidth
\newcommand\thickcline[1]{%
  \noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
  \cline{#1}%
  \noalign{\vskip\arrayrulewidth}%
  \noalign{\global\arrayrulewidth\savedwidth}%
}

% \thickhline command for thick horizontal lines that span the table
\newcommand\thickhline{\noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
\hline
\noalign{\global\arrayrulewidth\savedwidth}}


% Remove comment for double spacing
%\usepackage{setspace} 
%\doublespacing

% Text layout
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Bold the 'Figure #' in the caption and separate it from the title/caption with a period
% Captions will be left justified
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,justification=raggedright,singlelinecheck=off]{caption}
\renewcommand{\figurename}{Fig}

% Use the PLoS provided BiBTeX style
\bibliographystyle{plos2015}
% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother



% Header and Footer with logo
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
%\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
%\setlength{\headheight}{27.023pt}
%\lhead{\includegraphics[width=2.0in]{PLOS-submission.eps}}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}
\lfoot{\today}

%% TEMPORARY FIGURES (REMOVE BEFORE SUBMISSION)
% \usepackage[svgpath=./figs/]{svg}
\usepackage{graphicx}
\graphicspath{{./betaSeriesSimulations/outputs/}{./BetaSeriesRealDataAnalysis/nibsAnalysis/outputs/}{./BetaSeriesRealDataAnalysis/firstLevelAnalysis/outputs/}{./BetaSeriesRealDataAnalysis/introductionFigures/outputs/}}
\usepackage{float}
\usepackage[caption=false]{subfig}
\usepackage{csvsimple}
\usepackage{chngcntr}
\counterwithout{figure}{section}

%% Include all macros below

\newcommand{\lorem}{{\bf LOREM}}
\newcommand{\ipsum}{{\bf IPSUM}}

%% END MACROS SECTION


\begin{document}
\vspace*{0.2in}

% Title must be 250 characters or less.
\begin{flushleft}
{\Large
\textbf\newline{Beta series correlations} % Please use "sentence case" for title and headings (capitalize only the first word in a title (or heading), the first word in a subtitle (or subheading), and any proper nouns).
}
\newline
% Insert author names, affiliations and corresponding author email (do not include titles, positions, or degrees).
\\
James Kent\textsuperscript{1*},
Michelle Voss\textsuperscript{1},
%Name3 Surname\textsuperscript{2,3\textcurrency},
%Name4 Surname\textsuperscript{2},
%Name5 Surname\textsuperscript{2\ddag},
%Name6 Surname\textsuperscript{2\ddag},
%Name7 Surname\textsuperscript{1,2,3*},
%with the Lorem Ipsum Consortium\textsuperscript{\textpilcrow}
\\
\bigskip
\textbf{1} Psychology Department, University of Iowa, Iowa City, Iowa, United States
%\\
%\textbf{2} Affiliation Dept/Program/Center, Institution Name, City, State, Country
%\\
%\textbf{3} Affiliation Dept/Program/Center, Institution Name, City, State, Country
%\\
\bigskip

% Insert additional author notes using the symbols described below. Insert symbol callouts after author names as necessary.
% 
% Remove or comment out the author notes below if they aren't used.
%
% Primary Equal Contribution Note
%\Yinyang These authors contributed equally to this work.

% Additional Equal Contribution Note
% Also use this double-dagger symbol for special authorship notes, such as senior authorship.
%\ddag These authors also contributed equally to this work.

% Current address notes
% \textcurrency Current Address: Dept/Program/Center, Institution Name, City, State, Country % change symbol to "\textcurrency a" if more than one current address note
% \textcurrency b Insert second current address 
% \textcurrency c Insert third current address

% Deceased author note
% \dag Deceased

% Group/Consortium Author Note
% \textpilcrow Membership list can be found in the Acknowledgments section.

% Use the asterisk to denote corresponding authorship and provide email address in note below.
* james-kent@uiowa.edu

\end{flushleft}
% Please keep the abstract below 300 words
\section*{Abstract}
Understanding how networks dynamically organizing during different conditions
of a task is under validated.
An increasing popular measure to estimate which brain regions correlate with
each other during different task conditions is beta series correlations.
In combination with an increasing number of fast event related designs to
increase behavioral and statistical efficiency, the need to validate
beta series correlations is growing.
Two common ways to generate beta series are Least Squares All (LSA) and
Least Squares Separate (LSS).
Our simulations show LSS outperforms LSA across a variety of inter event
intervals and numbers of total events.
However, real data presents a less straight forward interpretation
where LSS may show more sensitivity, but less specificity relative to
LSA.
This research shows the importance of validation using both simulations
and real data and impacts how future studies should design their tasks
to improve detectability of conditional organization of brain networks.


% Please keep the Author Summary between 150 and 200 words
% Use first person. PLOS ONE authors please skip this step. 
% Author Summary not valid for PLOS ONE submissions.   
% \section*{Author summary}
% Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur eget porta erat. Morbi consectetur est vel gravida pretium. Suspendisse ut dui eu ante cursus gravida non sed sem. Nullam sapien tellus, commodo id velit id, eleifend volutpat quam. Phasellus mauris velit, dapibus finibus elementum vel, pulvinar non tellus. Nunc pellentesque pretium diam, quis maximus dolor faucibus id. Nunc convallis sodales ante, ut ullamcorper est egestas vitae. Nam sit amet enim ultrices, ultrices elit pulvinar, volutpat risus.

\linenumbers

% Use "Eq" instead of "Equation" for equation citations.
\section*{Introduction}
\label{intro}

The field of human imaging neuroscience has moved towards interrogating networks of brain regions
over individual brain regions.
Broadly defined, a brain network is a collection of widespread brain regions who share information ~\cite{Uddin2019}.
Brain networks have primarily been investigated while participants are at rest, there
is a raising popularity to observe brain networks while participants perform tasks ~\cite{Cole2014a}.
There is also a rising popularity to measure dynamic brain networks where brain regions change
what network they participate in over time ~\cite{Sakoglu2008,Hindriks2016}.
However, There has not been significant validation and investigation of brain networks
when participants engage in tasks with interleaved conditions that could induce
different brain networks dynamically.
In other words, brain networks have not been investigated within fast event related designs ~\cite{Buckner1998}.
We seek to validate and compare two methods that can measure brain responses to events that occur
close in time.

The overarching method being investigated is beta series correlations (BSC) ~\cite{Rissman2004,Mumford2012,Turner2012a,Abdulrahman2016}
There are two main approaches to estimate the Beta Series for BSC: Least Squares All (LSA) and Least Squares Separate (LSS) ~\cite{Mumford2012}.
Both approaches of beta series estimation seek to derive single event estimates that represent a brain region's activity
at each individual event.
An event is defined as "a stimulus or participant response recorded during a task." ~\cite{Gorgolewski2016}
Where task is defined as "a set of structured activities performed by the participant." ~\cite{Gorgolewski2016}
The single event estimates become difficult to estimate when trials are close together,
in other words, less than the time it takes for the Blood Oxygen Level Dependent (BOLD) response to resolve \ref{fig:introhrf}.
Such designs are called fast event related designs.
The reason these single events are difficult to estimate in fast event related designs comes from
the sluggish BOLD response \ref{fig:introhrf}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{introduction-hrf}
  \caption{
    Model of the Hemodynamic Response Function (HRF) ~\cite{Glover1999} at a
    typical resolution of an fMRI scan (2 seconds).
    The x-axis represents time in seconds and the y-axis is arbitrary units.
    Fast event related designs with inter event intervals (IEIs) at or faster than time to peak
    response (e.g., 4-6 seconds), need to account for the overlapping signals.
  }
  \label{fig:introhrf}
\end{figure}

The BOLD response is an indirect measure of neuronal activity that take approximately 6 seconds to
peak and around 16-32 seconds to effectively resolve.
If events are occurring (on average) 4 seconds apart, the difficulty of single event estimation
becomes apparent.
One does not know whether BOLD activity should be attributed to a target event or an
adjacent event.
LSA and LSS approach this problem differently.
LSA, namely, ignores this problem providing a high variance, but low bias measure; while LSS provides
a lower variance; but more biased measure.
To understand how LSA and LSS tackle single event estimation, it is necessary to introduce
the General Linear Model (GLM).
GLMs are a mainstay in the neuroimaging literature, allowing researchers to model
a response that approximates the BOLD response shape and linearly scale the response
to best match the data.
The multiplicative that linearly scales the model BOLD response is known as a beta.
The beta in the GLM is where the beta in beta series comes from.
This beta is often interpreted as the amplitude of the response.
In a traditional GLM, events of the same type will be grouped together
to provide a robust estimate of whether a particular region or set of regions are
active relative to some other baseline.

\begin{figure}[H]
  \centering
  \includegraphics{introduction-normalGLM}
  \caption{
    An example of a design matrix seen in a traditional GLM used in fMRI ~\cite{Friston1995}.
    There is a single column for each condition, resulting in two columns (intercept column ignored for clarity).
    With this design you can answer questions about which voxels are more or less active in one condition
    versus another, but you cannot see which voxels vary together over stimulus presentations.
  }
  \label{fig:introGLM}
\end{figure}

That approach, however, does not tell you which regions are acting in concert
in response to the event type.
It could be the case that for half of the events of the same type two regions are active,
and for the other half, another two regions are active.
The traditional GLM will not be able differentiate the different pairs of regions.
LSS and LSA, on the other hand, propose to be able to separate the different pairs of regions.
LSA takes a variant of the traditional GLM whereby instead of providing a beta
estimate for a group of events, each event gets it's own beta estimate in a single GLM ~\ref{fig:introlsa}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{introduction-lsa}
  \caption{
    Left shows an example design matrix for LSA where each event gets its own column.
    Since we receive a beta estimate per column, we end up with as many beta estimates as there
    are events.
    We can combine those beta estimates to create a beta series (Right) for each condition.
    In this example we measured beta series for two voxels, allowing us to
    correlate the betaseries from one voxel to another.
    We can perform the correlation for the two conditions.
    The arrows on the design matrix (left) correspond to the beta estimates of those events
    on the shaded regions (right).
  }
  \label{fig:introlsa}
\end{figure}

LSS differs from LSA by fitting a separate GLM for each event, where in each model a target
event is fit and the rest of the events are grouped together and given separate beta estimates ~\ref{fig:introlss}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{introduction-lss}
  \caption{
    Left shows an example design matrix for LSS where each event gets its own model
    (intercept excluded for clarity).
    The target event (outlined in red) comes from either condition 0 or 1.
    For example, if the target event is from condition 1, the remaining condition 1 events
    get their own column, and all of the condition 0 events get their own column
    Since we receive a beta estimate per model, we end up with as many beta estimates as there
    are events.
    We can combine those beta estimates to create a beta series (Right) for each condition.
    In this example we measured beta series for two voxels, allowing us to
    correlate the betaseries from one voxel to another.
    We can perform the correlation for the two conditions.
    The arrows on the design matrix (left) correspond to the beta estimates of those events
    on the shaded regions (right).
  }
  \label{fig:introlss}
\end{figure}

The target trial estimate for each model is taken to form a beta series.
Harkening back to the sluggish BOLD response, LSA suffers when the events are close together,
since the GLM cannot reliably attribute which BOLD response should correspond to which event ~\ref{fig:introGLM}.
LSS attempts to reduce the model confusion by only having one single event estimate per model,
so the non-target events have their beta influenced by multiple observations, loosening the
constraint that adjacent events to the target event need to be orthogonal (i.e. independent) of each other.
While previous work has simulated beta series and evaluated beta series on real data,
several key gaps remain ~\cite{Mumford2014a,Mumford2012,Turner2012a,Abdulrahman2016,Cisler2012,Arco2018}.
One, simulations have not taken into account realistic noise structure of fMRI data.
Two, simulations have not used optimal fast event related designs, only random designs. 
Three, empirical selections of signal to noise ratios have not been considered.
Four, a quantitative comparison/validation of LSA and LSS estimation for BSC has not been done.
The present work fills these gaps and provides recommendations for further research
using LSA and LSS.

\section*{Materials and methods}
\label{methods}

Testing and validation of beta series correlations followed three stages.
First, beta series correlations were tested in simulations across different
optimized experimental designs.
Second, beta series correlations were tested in simulations using an experimental
design that was used to collect real data.
Third, beta series correlations were validated in real task data collected from
participants.
Resting state data collected from the same participants was used as a null
control for beta series correlations.
Since there is no expectation of betaseries correlations to change
during resting state, we can get a measure of spurious results found
in beta series correlations.

\subsection*{BetaSeries Correlations}
\label{methods:bsc}

\subsubsection*{Beta Series Modeling}
\label{methods:bsc_model}

The LSS models were generated for each event in
the task following the method described in \cite{Turner2012a}, using
Nistats 0.0.1b2.\\
Prior to modeling, preprocessed data were masked, and mean-scaled over
time.
Mean scaling was not applied when calculating CNR and AVNR so the
beta estimates would be in the original BOLD units.
For each event, preprocessed data were subjected to a GLM
in which the event was modeled with its own regressor, while
all other events from that condition were modeled in a second regressor,
and other conditions were modeled in their own regressors.
So if the task has the conditions switch, repeat, and single, 
a single GLM would have 4 event regressors, 1 for the target
event, and 3 for the remaining conditions.

The LSA model was generated following the method described in
\cite[Rissman 2004]{Rissman2004}, using Nistats 0.0.1b2.
Each event was given its own regressor in a single GLM, such that
if the experiment had 100 events, there would be 100 regressors in the GLM.

Each event regressor was convolved with a \cite[glover hemodynamic response
function]{Glover1999}.
In addition to event regressors, average white matter signal, average csf signal,
cosine basis set high pass regressors, the initial four non stead state volumes, 
and motion outliers were included
in the model as calculated in the Preparing fMRI section.
AR(1) prewhitening was applied in each model to account
for temporal autocorrelation.

After fitting each model, the parameter estimate (i.e., beta) map
associated with the target event's regressor was retained and
concatenated into a 4D image with all other events from the same
condition, resulting in a set of X 4D images where X refers to the
number of conditions in the task.
The number of volumes in each 4D image represents the number of events in that condition.


\subsubsection*{Atlas Correlation Analysis}
\label{methods:atlas-corr-analysis}

The beta series 4D image for each condition in the task was subjected to
an region of interest to region of interest (ROI-to-ROI) correlation analysis
to produce condition-specific correlation matrices.
For the simulation data, ROI-to-ROI correlations were calculated by
treating each voxel as an ROI.
In the real data; two atlases were used to generate ROI-to-ROI correlation matrices.
We created an activation atlas representing regions that were
consistently activated across event conditions (see \nameref{methods:task-switch}).
This atlas has coverage across several cortical and subcortical regions.
The second atlas, \cite[Schaefer Atlas (400 parcels, 17 networks)]{Schaefer2017}, was
used to comprehensively cover the cortex and demonstrate robustness of results.

Outlier beta estimate volumes were identified and discarded using a
modified Nipype function for outlier detection
(\href{https://github.com/HBClab/NiBetaSeries/blob/a45c0a1f/src/nibetaseries/interfaces/nilearn.py#L153}{see here}) ~\cite{Crosby1994}.
The correlation coefficient estimator used for generating correlation matrices
was empirical covariance, as implemented in Nilearn 0.4.2
\cite{Abraham2014}.
Correlation coefficients were converted to normally-distributed z-values using
Fisher's r-to-z conversion \cite{Fisher1915}.

In the participant data, BSC generated correlation matrices for each condition (switch, repeat, single),
each method, (LSA and LSS), each data type (real and null), and each participant (N=40).
The first check performed was contrasting the real switch condition and null switch condition
to ensure BSC from a task are different than BSC from null data.
A ttest was run on each ROI-ROI pair for the activation atlas, totaling 190 comparisons
between task and null.
The results were corrected for multiple comparisons (Benjamini/Hochberg).
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/90fafb5b83b2e1bfade61a9fb1a87f225efaa95f/nibsAnalysis/BetaSeriesAnalysis.ipynb}{see here for relevant code})

We next contrasted $switch - single$, $repeat - single$, and $switch - repeat$, for LSS/LSA in both
real and null data.
Positive rates were calculated for LSA and LSS by dividing the number of positive results (p < 0.05)
in the real data with the number of positives found in the null data.

\subsection*{Beta Series Correlation Simulations}
\label{methods:bsc-simulations}

To assess the validity and power of beta series correlations,
we simulated two voxels of fMRI timeseries data and convolved short (0.2 second)
task onsets with double gamma functions
and added the responses to the timeseries~\cite{Glover1999,Welvaert2011}.
We used \cite[fmrisim from the brainiak toolbox]{Ellis2020} to generate a
two voxel fMRI timeseries containing drift, autocorrelation ($\rho$ = 0.5), phsysiological noise,
task related movement, and scanner noise \ref{fig:simulation_example}.
Noise features were all weighted equally in the simulations.

\begin{figure}[H]
  \centering
  \includegraphics{methods-simulation_example}
  \caption{
    Example of predicted BOLD from a task design (thick grey line), real BOLD
    from a participant (see \nameref{methods:task-switch}), and simulated BOLD
    from \cite[fmrisim]{Ellis2020}.
  }
  \label{fig:simulation_example}
\end{figure}

For all simulations the time of repetition was set at 2 seconds.
We varied the contrast-to-noise ratio (CNR) using the amplitude of the activation
divided by the standard deviation of the noise~\cite{Welvaert2013a}.
In other words, we used the average of the beta estimates and divided by the standard
deviation of the residuals output by the LSA model.
Another parameter deemed critical by previous work is the standard deviation
of the raw beta estimates relative to the standard deviation of the noise~\cite{Abdulrahman2016},
so we varied that measure as well.
\cite[Since Abdulrahman \& Henson (2016)]{Abdulrahman2016} also called their measure
CNR, we've decided to rename it as Activation Variance to Noise Ratio (AVNR), to
contrast it with our definition of CNR.

To generate realistic numbers for simulating timeseries at varying CNRs and AVNRs
we used an unpublished dataset on task switching in older adults (N=40).
We ran LSS/LSA to get both trial estimates of activation (i.e., betas)
as well as residuals from the model.
To calculate CNR, several steps were taken.
First, we masked the betaseries using the Schaefer or Activation atlases (see \nameref{methods:atlas-corr-analysis}).
Second, we took the absolute value of all masked beta estimates for a participant.
Third, we took the median beta estimates over all trial volumes resulting
in a median beta estimate amplitude for all ROIs.
Fourth, we took the standard deviation of the residuals for each ROI.
Fifth, we divided the median amplitude beta estimates by the standard deviation of the residuals
for each ROI.
Sixth, we took either the mean or max CNR across all ROIs to provide a reasonable estimate
and upper bound of CNR.
Calculating AVNR followed the same procedure as CNR with the exception of the first two steps.
First, we took the standard deviation of the beta estimates, then we followed steps three through six above
on the standard deviation of the beta estimates (as opposed the amplitude).
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/90fafb5b83b2e1bfade61a9fb1a87f225efaa95f/nibsAnalysis/cnr_trial_variability.ipynb}{see here for the relevant code})

\begin{table}[H]
\begin{adjustwidth}{0in}{0in} % Comment out/remove adjustwidth environment if table fits in text column.
\centering
\caption{
{\bf Summary of AVNR and CNR measures in Real Data}}
\begin{tabular}{|l+l+l|l|l|l|}
\hline
Atlas & Method & CNR (mean) & CNR (max) & AVNR (mean) & AVNR (max)\\ \thickhline
$Schaefer$ & $LSS$ & 0.71 & 1.81 & 1.03 & 2.33\\ \hline
$Activation$ & $LSS$ & 0.99 & 1.58 & 1.42 & 2.18\\ \hline
$Schaefer$ & $LSA$ & 1.02 & 2.48 & 1.54 & 3.61\\ \hline
$Activation$ & $LSA$ & 1.42 & 2.18 & 2.15 & 3.26\\ \hline
\end{tabular}
The average and maximum CNR and AVNR for both atlases (Schaefer and Activation)
as well as estimation method (LSS and LSA).
LSS tends to give lower CNR/AVNR since the measure sacrifices
variance for bias, unlike LSA, which remains unbiased.
\label{table1}
\end{adjustwidth}
\end{table}

We derived CNRs of 1 and 2 as and AVNRs of 1 and 2 as reasonable values from the dataset \ref{table1}.
We can manipulate CNR and AVNR independently to determine whether simulated BOLD response variation
impact beta series correlation's ability to recapture the true correlation or if the simulated BOLD
response magnitude is more important.
The choice of onset times was varied based on average inter-event-interval (IEIs).
The IEI is the time from the previous event onset to the next event onset.
We chose average IEIs at 2, 4, 6, and 8 seconds to reflect a common range of IEIs
for fast event related design experiments ~\cite{Hennigan2015,Dichter2007,Goghari2009}.
We also varied number of events, choosing 15, 30, 45, and 60 events per condition,
which also appear to be common selections for fast event related design experiments.
The optimization of selecting event onsets was done with neurodesign ~\cite{Durnez2018}.
We chose to optimize A-Optimality for onsets selection using the genetic algorithm implemented
in neurodesign, selecting onsets with an exponential distribution.
The top 20 designs were chosen from neurodesign to reduce the likelihood
that the simulation results are an artifact of idiosyncrasies
of the optimized experimental design.

The beta weights for each voxel were chosen from a multivariate normal distribution
with a mean of one and with a fixed ground truth correlation between the two voxels 
(varying between 0.0-0.9) with AVNR of either 1 or 2.
The ground truth correlation was varied to ensure the ground truth correlations were above
and below the correlations of the noise timeseries between the two voxels,
since both voxels had shared noise sources from simulated motion.
The beta weights were convolved with a hemodynamic response function and scaled
relative to the noise standard deviation to CNRs of 1 or 2.
(\href{https://github.com/jdkent/betaSeriesSimulations/tree/38dfbf2d83a8ab742d134c490b850ad893c8b4c7/beta_sim}{see here for simulation code})

200 simulations were run for each combination of event number
(15, 30, 45, 60) IEI (2, 4, 6, 8),  CNR (1, 2), AVNR (1, 2), condition (c0, c1),
and ground truth correlation
(0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
resulting in 256,000 total simulations.
Within each 200 simulation combination, the 20 top task designs specified by
neurodesign were evenly applied to the simulations, resulting in 10 simulations
using the same design.
Each simulation of two voxels can be imagined as a unique participant or run from
the same participant.

To measure validity for power analyses, we first ensured that we have
the expected false positive rate when there is no difference between samples.
we took two samples (n=50) with the same ground truth correlation (e.g., 0.1)
matching on event number, IEI, CNR, and AVNR, and ran a ttest to measure if the samples
were statistically significantly different.
Since the ground truth correlation is the same between samples,
we expect a false positive rate of \%5 at an alpha of 0.05.
We repeated this process 10,000 times to measure the false positive rate as
the number of statistically significant ttests.

Once the false positive rate was established, we established power with the same method as above,
but with samples containing different ground truth correlations.
We selected two samples where there was 0.1 (Pearson's r) difference between the samples.
0.1 difference was chosen based on reported differences found in other published
reports as well as the dataset used in this report ~\cite{Katsura2014,Lee2017,Turner2017,Lin2019,Huang2019}.
This process was also repeated 10,000 times to establish power.
Thus we detected how well correlation differences could be detected
with different task design and noise parameters.

Simulating data using the same task design as the real data followed the same
procedure as above, varying CNR (1, 2), AVNR (1, 2), condition (switch, repeat, single),
and ground truth correlation (0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9).
IEI and event number were not varied since those parameters are fixed by the
task design.
Each parameter combination was simulated 1000 times resulting in a total of 240,000 simulations.
False positive rate and power were evaluated using the same procedure as the other simulated data.

\subsection*{Real Data Validation}
\label{methods:task-switch}

To validate the betaseries simulations we used an unpublished dataset
of older adults (N=61, 31 female, age=71.75$\pm$4.77, education=17.07$\pm$2.66)
performing a mixed task switching task.
Numbers reported are mean$\pm$standard deviation.
Prior to any experimentation, participants provided verbal and written consent
to participate in the research presented in this manuscript, which was approved
by the University of Iowa's Institution Review Board.
21 participants were excluded in the primary analysis for having a
framewise displacement of over 0.5mm for over a 100 volumes,
resulting in a final N of 40.
The task switch task was a mixed block/event related design containing
5 blocks (2 single task blocks and 3 mixed task blocks).
There was a 30 second rest between each block.
There were 30 trials during each single trial block,
and for the 3 mixed blocks there were 48 repeat trials and 40 switch trials total.
The single tasks consisted of identifying a number between
1 and 10 excluding 5 as high/low or odd/even, using their left and right index fingers
on a fiber optic response pad.
Participants were cued to which task they were performing by the color of the square
the number was presented on.
Each stimulus was presented for 1.5 seconds, and participants were allowed
to respond within 2.0 seconds of stimulus onset.
The average IEI was 3.5 seconds following an exponential distribution.
All stimuli were presented using E-Prime.
Participants practiced an abridged version of this task in a mock scanner
prior to the real scan and had 4 practice trials in the real scanner immediately
prior to performing the task to ensure proper finger placement and data acquisition.

Participants' average accuracy and reaction time were:
single, (92\%$\pm$27\%, 792ms$\pm$225ms); repeat, (89\%$\pm$31\%, 1001ms$\pm$278ms);
and switch, (83\%$\pm$36.8\%, 1108ms$\pm$289ms).
Due to data collection error, behavioral data were not collected for 3 participants
(\href{https://github.com/jdkent/BetaSeriesRealDataAnalysis/blob/90fafb5b83b2e1bfade61a9fb1a87f225efaa95f/summarizeBehavior/summarize_behavior.ipynb}{see here for relevent code})

The task switch bold \emph{fmriprep} output in MNI152NLin2009cAsym space
was analyzed with \emph{Nistats} for first and second level analyses.
we used mean white matter signal, mean cerebrospinal fluid signal,
discrete cosine basis filter (high pass filter), framewise displacement, the first four non-steady volumes, and
all identified motion outliers as regressors in the first level model for each participant
in addition to event onsets convolved with a double gamma function ~\cite{Glover1999}.
Each image was smoothed with a 6mm full-wide half-max kernel.
We derived all condition versus baseline contrasts: single, repeat, switch, as well as
additional contrasts for $switch - repeat$ and an F-test of all task conditions.
We ignored correctness of the participant's response since this was not important to
separate the impact of condition and error processing to validate BSC.

Second level analysis took a summary of the first level results presenting which
regions were robustly activated between participants.
For each contrast, the alpha was set to 0.01 with a cluster threshold of 10 voxels using
false discovery rate error control \ref{fig:stat_maps}.

\begin{figure}[H]
  \centering
  \subfloat{
    \includegraphics[width=\textwidth]{stat-map-single}
  }
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{
    \includegraphics[width=\textwidth]{stat-map-repeat}
  }
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{
    \includegraphics[width=\textwidth]{stat-map-switch}
  }
\end{figure}

\begin{figure}[H]
  \ContinuedFloat
  \centering
  \subfloat{
    \includegraphics[width=\textwidth]{stat-map-switchXrepeat}
  }
  \caption{
    Univariate statistical maps of second level results representing
    each condition relative to baseline, an F-test over all conditions,
    and the contrast "switch - repeat"}
  \label{fig:stat_maps}
\end{figure}

An activation atlas was generated based on an F-test across conditions
to identify regions that were reliably activated for all participants \ref{table:clusters}.
5mm spheres were drawn around each statistical peak (20 peaks total)
to form the activation atlas \ref{fig:methroimap}.

\begin{table}[H]
  \csvautotabular[separator=tab, no check column count]{./data/cluster_table.tsv}
  \caption{
    The peak MNI coordinates/Z-statistic identifying clusters/sub-clusters from the overall
    response contrast.
    These peaks were used to create regions of interest (ROIs) to form an atlas representative
    of the most consistently activated regions across conditions.
  }
  \label{table:clusters}
\end{table}


\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{stat-map-overall_resp_with_rois}
  \caption{
    ROIs drawn from the peak Z-score table, placing a sphere with a 5mm radius
    at each peak coordinate.
    The clusters are identified in their approximate locations
    with their ID.
  }
  \label{fig:methroimap}
\end{figure}

In addition to the task switching task, participants also completed
two 8 minute resting state runs.
We used the resting state runs as a null model for task switching.
While the task switch data had 471 volumes, each resting state run only had
240 volumes.
In order to match the length of the resting state data with the task data, we concatenated
the two resting state runs while cutting off the first 10 volumes of the second run
and interpolating 1 volume between the two runs, resulting in 471 volumes.
The interpolation helps transition the bold series from one run to the next,
analogous to interpolation performed when scrubbing high motion volumes \cite{Power2014a}. 
This null task data was treated equivalently to the task switching data for the
beta series correlation analysis.
(\href{https://github.com/jdkent/validateBetaSeries/tree/195ad5b4201971038dbbf8f73a3c537caf032743}{see relevant code here})

\subsection*{Scanner Parameters}
\label{methods:scanner}

MRI data were collected on a 3T GE Discovery 750w using a 32 channel head coil.
The anatomical T1w images were collected using a SPoiled Gradient-Recalled (SPGR) sequence
sagittally with a flip angle of 8$^{\circ}$, echo time of 3.168ms,
repetition time of 8.388ms, inversion time of 900ms, isometric voxel sizes of 1mm,
[256x256] acquisition matrix with 196 slices, field of view 25.6cm x 25.6cm.
The functional bold images were collected using a Gradient Echo sequence axially from
the bottom up sequentially with a flip angle of 80$^{\circ}$, echo time of 30ms,
repetition time of 2000ms, voxel sizes of 3.44x3.44x4.00 on a [64x64] acquisition matrix
with 37 slices, field of view 22cm x 22cm.

\subsection*{Preparing fMRI}
\label{methods:fmriprep}

Results included in this manuscript come from preprocessing performed
using \emph{fMRIPrep} 1.5.7 (\cite{fmriprep1}; \cite{fmriprep2}; RRID:SCR\_016216),
which is based on \emph{Nipype} 1.4.0
(\cite{nipype1}; \cite{nipype2}; RRID:SCR\_002502).


\subsubsection*{Anatomical data preprocessing}
\label{methods:anat}

The T1-weighted (T1w) image was corrected for intensity non-uniformity
(INU) with \texttt{N4BiasFieldCorrection} \cite{n4}, distributed with
ANTs 2.2.0 \cite[RRID:SCR\_004757]{ants}, and used as T1w-reference
throughout the workflow.
The T1w-reference was then skull-stripped with a \emph{Nipype} implementation
of the \texttt{antsBrainExtraction.sh} workflow (from ANTs), using OASIS30ANTs
as target template.
Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and
gray-matter (GM) was performed on the brain-extracted T1w using
\texttt{fast} \cite{fsl_fast} [FSL 5.0.9, RRID:SCR\_002823,][].
Brain surfaces were reconstructed using \texttt{recon-all} \cite{fs_reconall},
[FreeSurfer 6.0.1, RRID:SCR\_001847,][] and the brain mask estimated
previously was refined with a custom variation of the method to
reconcile ANTs-derived and FreeSurfer-derived segmentations of the
cortical gray-matter of Mindboggle \cite[RRID:SCR\_002438,]{mindboggle}.
Volume-based spatial normalization to one standard space (MNI152NLin2009cAsym)
was performed through nonlinear registration with \texttt{antsRegistration}
(ANTs 2.2.0), using brain-extracted versions of both T1w reference and the T1w template.
The following templates were selected for spatial normalization: \emph{ICBM 152 Nonlinear
Asymmetrical template version 2009c} {[}\cite{mni152nlin2009casym},
RRID:SCR\_008796; TemplateFlow ID: MNI152NLin2009cAsym{]}.

\subsubsection*{Functional data preprocessing}
\label{methods:func}

For each of the 2 BOLD runs found per subject,
the following preprocessing was performed.
First, a reference volume and its skull-stripped version were generated
using a custom methodology of \emph{fMRIPrep}.
Susceptibility distortion correction (SDC) was omitted.
The BOLD reference was then co-registered to the T1w reference using \texttt{bbregister}
(FreeSurfer) which implements boundary-based registration \cite{bbr}.
Co-registration was configured with six degrees of freedom.
Head-motion parameters with respect to the BOLD reference (transformation matrices,
and six corresponding rotation and translation parameters) are estimated before any
spatiotemporal filtering using \texttt{mcflirt} \cite[FSL 5.0.9,]{mcflirt}.
The BOLD time-series were resampled into a standard space, correspondingly
generating the following \emph{spatially-normalized, preprocessed BOLD runs}:
MNI152NLin2009cAsym.
Several confounding time-series were calculated based on the \emph{preprocessed BOLD}:
% only used a subset of the confounding variables
framewise displacement (FD) and two region-wise global signals.
FD was calculated for each functional run, using its
implementation in \emph{Nipype} \cite[following the definitions
by]{power_fd_dvars}.
The two global signals were extracted within the
cerebrospinal fluid and the white matter masks.
High-pass filtering the \emph{preprocessed BOLD} time-series was done using
a discrete cosine filter with 128s cut-off.
The head-motion estimates calculated in
the correction step were also placed within the corresponding confounds file. 
Frames that exceeded a threshold of 0.5 mm FD or 1.5 standardised DVARS
were annotated as motion outliers.
An additional 4 frames at the beginning of each run were also
annotated as outliers to allow the magnet to reach equilibrium.

All resamplings can be performed with \emph{a single interpolation step} by composing all the pertinent
transformations (i.e.~head-motion transform matrices, co-registrations to anatomical
and output spaces).
Gridded (volumetric) resamplings were performed using \texttt{antsApplyTransforms} (ANTs),
configured with Lanczos interpolation to minimize the smoothing effects of other kernels
\cite{lanczos}.

\subsection*{Software Dependencies}
\label{methods:software-dependencies}

The results in this manuscript are dependent on many open source
libraries, while we have inevitably missed providing all due credit,
we would like to acknowledge some of the main libraries used in 
\emph{fMRIPrep} 1.5.7 \cite{fmriprep1} and \emph{NiBetaSeries} 0.6.0 \cite{Kent2018}.

Many internal operations of \emph{fMRIPrep} use \emph{Nilearn} 0.6.1
\cite[RRID:SCR\_001362]{nilearn}, mostly within the functional
processing workflow. For more details of the pipeline, see
\href{https://fmriprep.readthedocs.io/en/latest/workflows.html}{the
section corresponding to workflows in \emph{fMRIPrep}'s documentation}.

Additional libraries used in the \emph{NiBetaSeries} workflow include
\emph{Pybids} 0.9.5 \cite{Yarkoni2019}, \emph{Niworkflows} 1.0.4,
\emph{Nibabel} 2.4.1, \emph{Pandas} 0.24.2 \cite{McKinney2010}, and
\emph{Numpy} 1.18.1 \cite{VanDerWalt2011, Oliphant2006}.

In addition to the data analysis, visualization of results depended
on matplotlib \cite{Hunter2007}, seaborn \cite{Waskom2020}, nilearn,
jupyter notebooks \cite{Kluyver2016a}, and the packages they depend on.

% For figure citations, please use "Fig" instead of "Figure".
% Nulla mi mi, Fig~\ref{fig1} venenatis sed ipsum varius, volutpat euismod diam. Proin rutrum vel massa non gravida. Quisque tempor sem et dignissim rutrum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi at justo vitae nulla elementum commodo eu id massa. In vitae diam ac augue semper tincidunt eu ut eros. Fusce fringilla erat porttitor lectus cursus, \nameref{S1_Video} vel sagittis arcu lobortis. Aliquam in enim semper, aliquam massa id, cursus neque. Praesent faucibus semper libero.

% Place figure captions after the first paragraph in which they are cited.
% \begin{figure}[!h]
% \caption{{\bf Bold the figure title.}
% Figure caption text here, please use this space for the figure panel descriptions instead of using subfigure commands. A: Lorem ipsum dolor sit amet. B: Consectetur adipiscing elit.}
% \label{fig1}
% \end{figure}

% Results and Discussion can be combined.
\section*{Results}
\label{results}

\subsection*{Beta Series Correlation Simulations}
\label{results:bsc-simulations}

The first stage of BSC testing focused on simulations with varying event numbers,
IEIs, CNRs, AVNRs, and estimation method.
For proper interpretation of the power analyses, we first established whether
a 5\% false positive rate was found across all combinations of
event numbers, IEIs, CNRs, AVNRs, and estimation method.
We found a nominal \%5 false positive rate held across all combinations
of parameters \ref{fig:res_sim_fpr}.

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{avnr-1_fpr}}

  \subfloat{\includegraphics[width=\textwidth]{avnr-2_fpr}}

  \caption{
    LSA/LSS both show a \%5 false positive rate for all conditions.
    Each bar represents a sample of 50 pairs of correlations (with no true difference)
    randomly pulled from a distribution of correlations 10,000 times.
  }
  \label{fig:res_sim_fpr}
\end{figure}

With the false positive rate established, we next observed how detectable a
correlation difference of 0.1 was across all parameters.

\begin{figure}[H]
  \centering
  \subfloat{\includegraphics[width=\textwidth]{avnr-1_smalldiff}}

  \subfloat{\includegraphics[width=\textwidth]{avnr-2_smalldiff}}

  \caption{
    Detection power of a small difference between conditions (r=0.1).
    LSS at least marginally outperforms LSA in most simulated experimental
    designs, with a large difference in power when IEI is 4 seconds and
    CNR is high.
    LSS appears to have an advantage in low CNR scenerios across the longer IEIs
    when AVNR is high.
    Each bar represents a sample of 50 pairs of correlations (with no true difference)
    randomly pulled from a distribution of correlations 10,000 times.
  }
  \label{fig:res_sim_smalldiff}
\end{figure}

While the IEI is 2, there is no discernable difference between LSS and LSA.
Since the simulated data were sampled at 2 second intervals, the result
corresponds to effectively presenting a stimulus during each sample.
With such overlapping simulated BOLD responses detecting a difference between conditions
is unlikely.
From an IEI of 4 seconds and upwards, LSS has an advantage over LSA.
Adding additional events above 30 appears to only help if the CNR is greater than 1.
Increasing the CNR improves power more than increasing the CVNR, although increasing either
provides a marked boost in detection power.
For LSS, the 8 second IEI does not appear to boost detection power beyond a 6 second IEI,
whereas LSA has a boost when AVNR and CNR are higher.
It's worth noting that even for 50 participants; not one power analysis showed
a power of 80\%, suggesting that larger sample sizes are required to detect a Pearson's r
difference of 0.1.

\subsection*{Task Switch Beta Series Correlation Simulations}
\label{results:bsc-taskswitch-simulations}

To make the simulations and the real data as analogous as possible
for comparison, we ran simulations using the same experimental design
that was used to collect the real data.

Again, we established a 5\% false positive rate \ref{fig:task_fpr}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{taskswitch-switchXrepeat_fpr}
  \caption{
    LSA/LSS both show a \%5 false positive rate for CNRs and AVNRs of 1 and 2. 
    Each bar represents a sample of 50 pairs of correlations (with no true difference)
    randomly pulled from a distribution of correlations 10,000 times.
  }
  \label{fig:task_fpr}
\end{figure}

With the false positive rate established, we next simulated the same 0.1 Pearson's r difference
between conditions \ref{fig:task_smalldiff}.
We compared the event conditions switch and repeat, but the results are similar for other
condition contrasts.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{taskswitch-switchXrepeat_smalldiff}
  \caption{
    Simulating power to detect a correlation difference of 0.1 between
    conditions.
    Each power plot represents a sample of 40 pairs of correlations
    randomly pulled from a distribution of correlations 10,000 times.
    The correlation pairs had a true difference 0.1.
    With a large CNR, the power for both LSS and LSA
    is maximal regardless of the true difference.
    With a small CNR, LSS has greater power to detect a difference.
  }
  \label{fig:task_smalldiff}
\end{figure}

Using this task design, AVNR has a minimal impact on detection power, while
doubling CNR nearly doubles detection power.
Again, we see LSS has an advantage over LSA in all conditions.
With this experimental design, 40 simulated participants were enough to achieve
a power of over 80\%, suggesting experimental design plays a large role in
detection power.

\subsection*{Task Switching Beta Series Correlations}
\label{results:bsc-taskswitch}

We looked at task switching data from the most lenient
contrast ($real - null$) to the most conserative contrast ($switch - repeat$)
to assess how well LSS and LSA detect correlational differences between conditions.
For the contrasts $switch - single$, $repeat - single$, and $switch - repeat$ we also
performed the same contrast in the null data to measure the specificity of each method.

The data from the Schaefer atlas is visualized as a matrix because of the large number of
regions.
The activation atlas is visualized using a glass brain to provide the reader a better sense
of the anatomy.

\subsubsection*{Real versus Null}
\label{results:bsc-taskswitchXNull}

We demonstrate a broad pattern where the correlation between pairs of
regions differ between task and null data using the Schaefer atlas,
and a more modest pattern using the activation atlas \ref{fig:act_taskvnull}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{data-both_atlas-schaefer_contrast-taskXnull}
  \caption{
    Real versus null. Correlation differences with a p-value less than 0.05.
    LSS (green), LSA (blue), and their overlap (yellow) are shown.
  }
  \label{fig:sch_taskvnull}
\end{figure}

We used the switch condition in the real data to evaluate the most cognitively demanding condition
relative to null data.
We see a broad pattern of results.
Qualitatively, both LSS and LSA show statistical significance between the Control B network and
Dorsal Attention A/B and Somatomotor A networks.
After FDR correction, LSS maintained 1,333 statistically significant differences,
whereas LSA only had 386 statistically significant differences.
The comparison using the Schaefer atlas give LSS a large advantage.
However, the pattern is much weaker using the activation atlas \ref{fig:act_taskvnull}.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{data-both_type-brain_atlas-activation_contrast-taskXnull}
  \caption{
    Real versus null. Correlation differences with a p-value less than 0.05.
    LSS (green), LSA (blue), and their overlap (yellow) are shown.
  }
  \label{fig:act_taskvnull}
\end{figure}

Using the activation atlas, LSA has a total of 16 significant results,
LSS has a total of 24, and their overlap is 7.
No statistically significant findings survive FDR correction, providing
weak evidence for the advantage of LSS.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SWITCH V SINGLE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Switch versus Single}
\label{results:bsc-switchXsingle}

For this section and the remaining subsections, we will compare
the number of positives found in the real data relative to to null data for
the same condition contrasts.
If an estimation method identifies more positive results in both real and null data,
then the method may have good sensitivity, but poor specificity.

Within the Schaefer atlas, LSS and LSA perform similarly, with LSS showing more unique
results in the Somatomotor A network, and LSS showing more results in the Central
and Peripheral Visual networks \ref{fig:sch_switchvsingle}.
The real/null positive rate for LSS is 1.49 and for LSS it is 1.63.

\begin{figure}[H]
  \centering
  \subfloat{
    \includegraphics[width=0.5\textwidth]{data-task_atlas-schaefer_contrast-switchXsingle}
  }
  \subfloat{
    \includegraphics[width=0.5\textwidth]{data-null_atlas-schaefer_contrast-switchXsingle}
  }
  \caption{
    Switch versus single. Correlation differences with a p-value less than 0.05.
    LSS (green), LSA (blue), and their overlap (yellow) are shown.
  }
  \label{fig:sch_switchvsingle}
\end{figure}

The activation atlas for the contrast of $switch - single$
shows a slight advantage for the specificity of LSS relative to LSA \ref{fig:act_switchvsingle}.
LSS has a real/null positive ratio of 0.8 and LSA has a ratio of 0.4.

\begin{figure}[H]
  \centering
  \subfloat{
    \includegraphics[width=\textwidth]{data-task_type-brain_atlas-activation_contrast-switchXsingle}
  }
  \qquad
  \subfloat{
    \includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-switchXsingle}
  }
  \caption{
    Switch versus single. Correlation differences with a p-value less than 0.05.
    LSS (green), LSA (blue), and their overlap (yellow) are shown.
  }
  \label{fig:act_switchvsingle}
\end{figure}

While the schaefer atlas shows evidence of BSC
identifying potentially real correlation differences,
the activation atlas had more null results than real results.
Having more null results relative to real results gives less
confidence in BSCs overall.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% REPEAT V SINGLE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Repeat versus Single}
\label{results:bsc-repeatXsingle}

LSA shows a strong advantage over LSS with real/null positive ratio of 1.66,
relative to LSS with a ratio of 0.73.
Again LSA appears to find many statistically significant positives within the
Central and Peripheral Visual networks. 

\begin{figure}[H]
  \centering
  \subfloat{
    \includegraphics[width=0.5\textwidth]{data-task_atlas-schaefer_contrast-repeatXsingle}
  }
  \subfloat{
    \includegraphics[width=0.5\textwidth]{data-null_atlas-schaefer_contrast-repeatXsingle}
  }
  \caption{
    Repeat versus single. Correlation differences with a p-value less than 0.05.
    LSS (green), LSA (blue), and their overlap (yellow) are shown.
  }
  \label{fig:sch_repeatvsingle}
\end{figure}

The activation atlas for the contrast of $repeat - single$
mirrors the result found with the Schaefer atlas, namely LSA appears
more sensitive and specific relative to LSS \ref{fig:act_repeatvsingle}.
LSA has a real/null ratio of 2.80, while LSS has a ratio of 1.16.

\begin{figure}[H]
  \centering
  \subfloat{
    \includegraphics[width=\textwidth]{data-task_type-brain_atlas-activation_contrast-repeatXsingle}
  }
  \qquad
  \subfloat{
    \includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-repeatXsingle}
  }
  \caption{
    Repeat versus single. Correlation differences with a p-value less than 0.05.
    LSS (green), LSA (blue), and their overlap (yellow) are shown.
  }
  \label{fig:act_repeatvsingle}
\end{figure}

Across the Schaefer and activation atlas in the $repeat - single$ contrast,
LSA appears to outperform LSS.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SWITCH V REPEAT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Switch versus Repeat}
\label{results:bsc-switchXrepeat}

$Switch - Repeat$ is the most intriguing contrast because it is the most relevant
to many event related designs.
Whereas the previous contrasts did had events originating in different event blocks,
the switch and repeat conditions occur in close proximity to each other in the same block.

The Schaefer atlas shows LSS has more sensitivity but less specificity, whereas LSA
has less sensitivity but more specificity.
LSA has a real/null positive ratio of 2.28, and LSS has a real/null
positive ratio of 1.06.

\begin{figure}[H]
  \centering
  \subfloat{
    \includegraphics[width=0.5\textwidth]{data-task_atlas-schaefer_contrast-switchXrepeat}
  }
  \subfloat{
    \includegraphics[width=0.5\textwidth]{data-null_atlas-schaefer_contrast-switchXrepeat}
  }
  \caption{
    Switch versus single. Correlation differences with a p-value less than 0.05.
    LSS (green), LSA (blue), and their overlap (yellow) are shown.
  }
  \label{fig:sch_switchvrepeat}
\end{figure}

The activation atlas, on the other hand, shows that LSA has more sensitivity over LSS.
LSS does not find any statistically significant results in the activation atlas.
\begin{figure}[H]
  \centering
  \subfloat{
    \includegraphics[width=\textwidth]{data-task_type-brain_atlas-activation_contrast-switchXrepeat}
  }
  \qquad
  \subfloat{
    \includegraphics[width=\textwidth]{data-null_type-brain_atlas-activation_contrast-switchXrepeat}
  }
  \caption{
    Switch versus repeat. Correlation differences with a p-value less than 0.05.
    LSS (green), LSA (blue), and their overlap (yellow) are shown.
  }
  \label{fig:act_switchvrepeat}
\end{figure}

Overall, LSA is once again found to be a better estimator relative LSS in real data.

\subsection*{Debate on Results (not actually in paper)}
While the simulations reliably found LSS to be a better estimation method,
in the real data the results are mixed and in the most relevant contrast for
many event related designs $switch - repeat$,
LSA had the advantage over LSS.
The results become more muddied when the originally excluded data are included
in the analysis, then LSS appears to be more sensitive, but less specific, and LSA
becomes less sensitive.

\begin{itemize}
  \item Good participants (N=40)
  \begin{itemize} 
    \item Schaefer Atlas
    \begin{itemize}
      \item Task versus Null: LSS $>$ LSA
      \item Switch versus Single: LSS (1.49) $<$ LSA (1.62)
      \item Repeat versus Single: LSS (0.73) $<$ LSA (1.66)
      \item Switch versus Repeat: LSS (1.06) $<$ LSA (2.28)
    \end{itemize}
    \item Activation Atlas
    \begin{itemize}
      \item Task versus Null: LSS $>$ LSA
      \item Switch versus Single: LSS (0.80) $>$ LSA (0.40)
      \item Repeat versus Single: LSS (1.16) $<$ LSA (2.80)
      \item Switch versus Repeat: LSS (0.00) $<$ LSA (0.50)
    \end{itemize}
  \end{itemize}
  \item All Participants (N=61)
  \begin{itemize} 
    \item Schaefer Atlas
    \begin{itemize}
      \item Task versus Null: LSS $>$ LSA
      \item Switch versus Single: LSS (1.40) $<$ LSA (1.87)
      \item Repeat versus Single: LSS (0.81) $<$ LSA (1.42)
      \item Switch versus Repeat: LSS (1.70) $>$ LSA (0.44)
    \end{itemize}
    \item Activation Atlas
    \begin{itemize}
      \item Task versus Null: LSS $>$ LSA
      \item Switch versus Single: LSS (1.57) $>$ LSA (0.83)
      \item Repeat versus Single: LSS (1.83) $<$ LSA (2.5)
      \item Switch versus Repeat: LSS (1.50) $>$ LSA (0.00)
    \end{itemize}
  \end{itemize}
\end{itemize}

Total LSS "Wins": 8\\
Total LSA "Wins": 8\\

% \begin{table}[!ht]
% \begin{adjustwidth}{-2.25in}{0in} % Comment out/remove adjustwidth environment if table fits in text column.
% \centering
% \caption{
% {\bf Table caption Nulla mi mi, venenatis sed ipsum varius, volutpat euismod diam.}}
% \begin{tabular}{|l+l|l|l|l|l|l|l|}
% \hline
% \multicolumn{4}{|l|}{\bf Heading1} & \multicolumn{4}{|l|}{\bf Heading2}\\ \thickhline
% $cell1 row1$ & cell2 row 1 & cell3 row 1 & cell4 row 1 & cell5 row 1 & cell6 row 1 & cell7 row 1 & cell8 row 1\\ \hline
% $cell1 row2$ & cell2 row 2 & cell3 row 2 & cell4 row 2 & cell5 row 2 & cell6 row 2 & cell7 row 2 & cell8 row 2\\ \hline
% $cell1 row3$ & cell2 row 3 & cell3 row 3 & cell4 row 3 & cell5 row 3 & cell6 row 3 & cell7 row 3 & cell8 row 3\\ \hline
% \end{tabular}
% \begin{flushleft} Table notes Phasellus venenatis, tortor nec vestibulum mattis, massa tortor interdum felis, nec pellentesque metus tortor nec nisl. Ut ornare mauris tellus, vel dapibus arcu suscipit sed.
% \end{flushleft}
% \label{table1}
% \end{adjustwidth}
% \end{table}


%PLOS does not support heading levels beyond the 3rd (no 4th level headings).
% \subsection*{\lorem\ and \ipsum\ nunc blandit a tortor}
% \subsubsection*{3rd level heading} 
% Maecenas convallis mauris sit amet sem ultrices gravida. Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque. Quisque augue sem, tincidunt sit amet feugiat eget, ullamcorper sed velit. Sed non aliquet felis. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Mauris commodo justo ac dui pretium imperdiet. Sed suscipit iaculis mi at feugiat. 

% \begin{enumerate}
% 	\item{react}
% 	\item{diffuse free particles}
% 	\item{increment time by dt and go to 1}
% \end{enumerate}


% \subsection*{Sed ac quam id nisi malesuada congue}

% Nulla mi mi, venenatis sed ipsum varius, volutpat euismod diam. Proin rutrum vel massa non gravida. Quisque tempor sem et dignissim rutrum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi at justo vitae nulla elementum commodo eu id massa. In vitae diam ac augue semper tincidunt eu ut eros. Fusce fringilla erat porttitor lectus cursus, vel sagittis arcu lobortis. Aliquam in enim semper, aliquam massa id, cursus neque. Praesent faucibus semper libero.

% \begin{itemize}
% 	\item First bulleted item.
% 	\item Second bulleted item.
% 	\item Third bulleted item.
% \end{itemize}

\section*{Discussion}
\label{discussion}

% Nulla mi mi, venenatis sed ipsum varius, Table~\ref{table1} volutpat euismod diam. Proin rutrum vel massa non gravida. Quisque tempor sem et dignissim rutrum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi at justo vitae nulla elementum commodo eu id massa. In vitae diam ac augue semper tincidunt eu ut eros. Fusce fringilla erat porttitor lectus cursus, vel sagittis arcu lobortis. Aliquam in enim semper, aliquam massa id, cursus neque. Praesent faucibus semper libero~\cite{bib3}.
\subsection*{Simulation Conclusions}
\label{discussion:simulation-conclusions}

The main finding from the simulations is that LSS has greater detection power than LSA,
supporting other findings from the literature comparing LSS and LSA using MVPA and other
similar methods ~\cite{Mumford2012,Mumford2014a,Abdulrahman2016,Turner2012a}.
We found the best way to increase detection power is to increase IEI to 6 seconds and
have at least 30 trials per condition.

differences between simulations and real data:::\\
As mentioned in \nameref{methods:bsc-simulations}, each simulation represents
either a different participant or separate runs from the same participant.
The contrasts in the simulations are therefore most analogous to the $real - null$
contrast in \nameref{results:bsc-taskswitchXNull}.
Additionally, each simulation contains two conditions whose BOLD responses
are independent of each other.
There is likely temporal autocorrelation of BOLD responses across events,
which is not represented in the simulations ~\cite{Abdulrahman2016}.

The simulations contained physiological noise, task related motion, and drift.
however, all were all given equal weighting, which is unlikely how noise in real data
is represented.

We also did not simulate variations in HRF onset, which is likely to occur
as all BOLD responses to a stimulus do not occur at the time the stimulus onset.

While the simulations represented data without any preprocessing applied,
the real data had motion outliers, non steady state volumes,
CSF, and white matter signals accounted for in the model.
The additional regressors in the model reduce the degrees of freedom
and could impact the ability of the model to fit the data.
This would likely impact LSA more than LSS, since LSA already has
a large number of regressors representing each event.

Our CNR and AVNR values did not go as high as other manuscripts ~\cite{Mumford2012,Abdulrahman2016,Welvaert2013a}.
\cite[Welvaert]{Welvaert2013a} specifically calculated a range of CNRs using real data from a block design,
and got higher values than reported in this manuscript (values ranging from 0.01 - 95.73).

\cite[Abdulrahman \& Henson]{Abdulrahman2016} found when the noise between voxels has a higher correlation (i.e., coherence)
than the BOLD responses between voxels.
While we did not vary scan noise coherence relative to BOLD reponse coherence,
the average noise correlation between voxels is a Pearson's r of 0.67.
While the BOLD response correlations varied from a Pearson's r from (0.0-0.9).
The majority of the correlations simulated have greater noise coherence relative to
BOLD response coherence, yet the results suggest LSS has greater detection power regardless
if the relationship.

\subsection*{Task Switching Conclusions}
\label{discussion:taskswitching-conclusions}

The real data results were much less clear.
In combination with the analysis that used all the data;
the general statement could be that LSS is more sensitive and less specific
relative to LSA.

A surprising result is the lack of overlap between LSS and LSA results.
The lack of overlap is suprising because both LSS and LSA are purported to
measure the same underlying process.
An interesting relationship appears when we correlated the beta series from
LSA to LSS and plot average framewise displacement \ref{fig:lss_lsa_correlation}.
As the average framewise displacement increases and temporal signal to noise (TSNR)
decreases, the agreement between LSS and LSA decreases.
In other words, as noise in the data increases, the more divergent LSS and LSA become.
This suggests one reason for the disagreement is the noise still present in the included
data.
There appears to be a cluster of particpants with an average framewise displacement of
less than 0.2mm that have a high correlation between LSS and LSA.

\begin{figure}[H]
  \centering
  \includegraphics{lss_lsa_noise_relationship}
  \caption{
    The average correlation between LSA/LSS beta series across
    all ROIs in the activation atlas.
    Orange dots represent 21 participants that were not included
    in the original analysis and blue dots are the 40
    participants that were included.
    The size of the dots represent the temporal signal to noise
    ratio (TSNR), higher is better.
    The general pattern shows good correspondence between LSA and LSS
    when the average framewise displacement is low and TSNR is high.
  }
  \label{fig:lss_lsa_correlation}
\end{figure}

It could be argued the resting state data does not provide an adequate null model
to compare to the real task data because there is presumably no BOLD response at any
of the onset times.
Trying to model the BOLD response with no expectation of a BOLD response existing could lead
to large misfits and deviating beta estimates.
To test this, we evaluated average CNR and AVNR within the Schaefer and activation atlases in
the null data and compared it to the CNR and AVNR in the real data.
If the null data had much larger deviations in beta estimates, CNR and AVNR would be higher
in the null data relative to the real data.
For both LSS and LSA, the Schaefer atlas had statistically significantly higher
CNR/CVNR in the null data relative to the real data, whereas the activation atlas
did not show a statistically significant difference between null and real data.
This suggests model misfit may be a driving factor for spurious results.
We protected against extreme beta estimates by detecting and removing outliers, but model misfit
could still drive spurious results.
A proper null model would have bold responses at the onset times, but the bold responses
would be the same amplitude at every event.

\subsection*{Future Directions}

\begin{itemize}
  \item Run beta series correlations on larger dataset with enough power to reliably detect an effect
  \item Add ability to estimate CNR/AVNR in NiBetaSeries
  \item use t-statistic as opposed to raw beta estimates
  \item temporal/spatial analysis with Finite Impulse Responses \cite{Turner2012a}
  \item Add ability to simulate possible condition relationships in NiBetaSeries
  \item need to add "fake" mean hemodynamic response to normalize the data
  \item extend Cole's work (compare residual correlations with LSA/LSS)
  \item investigate graph theoretical measures to validate between task conditions and task/null.
  \item simulate variable onset of BOLD responses
\end{itemize}



\subsection{Limitations}
\section*{Conclusion}

% CO\textsubscript{2} Maecenas convallis mauris sit amet sem ultrices gravida. Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque. Quisque augue sem, tincidunt sit amet feugiat eget, ullamcorper sed velit. 

% Sed non aliquet felis. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Mauris commodo justo ac dui pretium imperdiet. Sed suscipit iaculis mi at feugiat. Ut neque ipsum, luctus id lacus ut, laoreet scelerisque urna. Phasellus venenatis, tortor nec vestibulum mattis, massa tortor interdum felis, nec pellentesque metus tortor nec nisl. Ut ornare mauris tellus, vel dapibus arcu suscipit sed. Nam condimentum sem eget mollis euismod. Nullam dui urna, gravida venenatis dui et, tincidunt sodales ex. Nunc est dui, sodales sed mauris nec, auctor sagittis leo. Aliquam tincidunt, ex in facilisis elementum, libero lectus luctus est, non vulputate nisl augue at dolor. For more information, see \nameref{S1_Appendix}.

\section*{Supporting information}

% Include only the SI item label in the paragraph heading. Use the \nameref{label} command to cite SI items in the text.
% \paragraph*{S1 Fig.}
% \label{S1_Fig}
% {\bf Bold the title sentence.} Add descriptive text after the title of the item (optional).

% \paragraph*{S2 Fig.}
% \label{S2_Fig}
% {\bf Lorem ipsum.} Maecenas convallis mauris sit amet sem ultrices gravida. Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque.

% \paragraph*{S1 File.}
% \label{S1_File}
% {\bf Lorem ipsum.}  Maecenas convallis mauris sit amet sem ultrices gravida. Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque.

% \paragraph*{S1 Video.}
% \label{S1_Video}
% {\bf Lorem ipsum.}  Maecenas convallis mauris sit amet sem ultrices gravida. Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque.

% \paragraph*{S1 Appendix.}
% \label{S1_Appendix}
% {\bf Lorem ipsum.} Maecenas convallis mauris sit amet sem ultrices gravida. Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque.

% \paragraph*{S1 Table.}
% \label{S1_Table}
% {\bf Lorem ipsum.} Maecenas convallis mauris sit amet sem ultrices gravida. Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque.

\section*{Acknowledgments}
%Cras egestas velit mauris, eu mollis turpis pellentesque sit amet. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam id pretium nisi. Sed ac quam id nisi malesuada congue. Sed interdum aliquet augue, at pellentesque quam rhoncus vitae.
\begin{itemize}
  \item "This research was supported in part through computational resources provided by The University of Iowa, Iowa City, Iowa."
  \item Data/people from the BETTER study 
\end{itemize}
\nolinenumbers

\bibliography{plos}
% Either type in your references using
% \begin{thebibliography}{}
% \bibitem{}
% Text
% \end{thebibliography}
%
% or
%
% Compile your BiBTeX database using our plos2015.bst
% style file and paste the contents of your .bbl file
% here. See http://journals.plos.org/plosone/s/latex for 
% step-by-step instructions.
% 
% \begin{thebibliography}{10}

% \bibitem{bib1}
% Conant GC, Wolfe KH.
% \newblock {{T}urning a hobby into a job: how duplicated genes find new
%   functions}.
% \newblock Nat Rev Genet. 2008 Dec;9(12):938--950.

% \bibitem{bib2}
% Ohno S.
% \newblock Evolution by gene duplication.
% \newblock London: George Alien \& Unwin Ltd. Berlin, Heidelberg and New York:
%   Springer-Verlag.; 1970.

% \bibitem{bib3}
% Magwire MM, Bayer F, Webster CL, Cao C, Jiggins FM.
% \newblock {{S}uccessive increases in the resistance of {D}rosophila to viral
%   infection through a transposon insertion followed by a {D}uplication}.
% \newblock PLoS Genet. 2011 Oct;7(10):e1002337.

% \end{thebibliography}



\end{document}
